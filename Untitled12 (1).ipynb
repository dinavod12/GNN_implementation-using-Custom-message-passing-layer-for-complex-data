{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6OX7EJifksq"
      },
      "outputs": [],
      "source": [
        "# Complex data File with positive combinations\n",
        "\n",
        "\n",
        "import json\n",
        "\n",
        "with open(\"/content/drive/MyDrive/DT1_Dict.json\") as f:\n",
        "    json_datas = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXhSncr3rW8x"
      },
      "outputs": [],
      "source": [
        "# Complex data File with negative combinations\n",
        "\n",
        "import json\n",
        "\n",
        "with open(\"/content/drive/MyDrive/N_RANDOM_Comb_dict (1).json\") as f:\n",
        "    neg_json_datas = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciSp-UdOhZap"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/string_to_number_mapping.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM7ss5OhXPLc",
        "outputId": "5a5aec83-2362-4c50-855a-2b248a2f3180"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.4.0\n"
          ]
        }
      ],
      "source": [
        "pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPVlzktDXPN7"
      },
      "outputs": [],
      "source": [
        "df_node = pd.read_csv(\"/content/drive/MyDrive/Proteins_for_MCODE.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ZoVjoERjXPQT",
        "outputId": "72d5116a-0b09-4d13-d697-6afe56f2b770"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a499eb0a-1acd-4652-9ab2-295fc2aec643\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Node1</th>\n",
              "      <th>Node2</th>\n",
              "      <th>MinimumDistance</th>\n",
              "      <th>MaximumDistance</th>\n",
              "      <th>AverageDistance</th>\n",
              "      <th>StdDev</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>56</td>\n",
              "      <td>57.949510</td>\n",
              "      <td>133.65941</td>\n",
              "      <td>92.577095</td>\n",
              "      <td>11.423593</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>28.534742</td>\n",
              "      <td>134.45079</td>\n",
              "      <td>82.553880</td>\n",
              "      <td>17.811756</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>107</td>\n",
              "      <td>7.596985</td>\n",
              "      <td>98.75455</td>\n",
              "      <td>46.010666</td>\n",
              "      <td>14.082993</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>77.086200</td>\n",
              "      <td>151.20248</td>\n",
              "      <td>113.425330</td>\n",
              "      <td>11.848842</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>524</td>\n",
              "      <td>72.927635</td>\n",
              "      <td>158.22409</td>\n",
              "      <td>118.794304</td>\n",
              "      <td>13.823575</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1918</th>\n",
              "      <td>3017</td>\n",
              "      <td>3018</td>\n",
              "      <td>4.335422</td>\n",
              "      <td>221.06035</td>\n",
              "      <td>110.863625</td>\n",
              "      <td>37.664210</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1919</th>\n",
              "      <td>3028</td>\n",
              "      <td>3034</td>\n",
              "      <td>24.405735</td>\n",
              "      <td>101.87383</td>\n",
              "      <td>60.430700</td>\n",
              "      <td>12.912899</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1920</th>\n",
              "      <td>3031</td>\n",
              "      <td>3032</td>\n",
              "      <td>4.521965</td>\n",
              "      <td>147.65855</td>\n",
              "      <td>65.546040</td>\n",
              "      <td>22.873760</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1921</th>\n",
              "      <td>3031</td>\n",
              "      <td>3033</td>\n",
              "      <td>8.512429</td>\n",
              "      <td>175.10011</td>\n",
              "      <td>85.473460</td>\n",
              "      <td>24.101467</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1922</th>\n",
              "      <td>3069</td>\n",
              "      <td>3070</td>\n",
              "      <td>96.578220</td>\n",
              "      <td>237.09047</td>\n",
              "      <td>168.180680</td>\n",
              "      <td>23.699362</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1923 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a499eb0a-1acd-4652-9ab2-295fc2aec643')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a499eb0a-1acd-4652-9ab2-295fc2aec643 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a499eb0a-1acd-4652-9ab2-295fc2aec643');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1895cc7f-1a10-4ff7-80e1-296efb52cd46\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1895cc7f-1a10-4ff7-80e1-296efb52cd46')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1895cc7f-1a10-4ff7-80e1-296efb52cd46 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_90e314c6-2f71-413e-bf88-21bb0364deab\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_node')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_90e314c6-2f71-413e-bf88-21bb0364deab button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_node');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      Node1  Node2  MinimumDistance  MaximumDistance  AverageDistance  \\\n",
              "0         1     56        57.949510        133.65941        92.577095   \n",
              "1         1     48        28.534742        134.45079        82.553880   \n",
              "2         1    107         7.596985         98.75455        46.010666   \n",
              "3         1    145        77.086200        151.20248       113.425330   \n",
              "4         1    524        72.927635        158.22409       118.794304   \n",
              "...     ...    ...              ...              ...              ...   \n",
              "1918   3017   3018         4.335422        221.06035       110.863625   \n",
              "1919   3028   3034        24.405735        101.87383        60.430700   \n",
              "1920   3031   3032         4.521965        147.65855        65.546040   \n",
              "1921   3031   3033         8.512429        175.10011        85.473460   \n",
              "1922   3069   3070        96.578220        237.09047       168.180680   \n",
              "\n",
              "         StdDev  Label  \n",
              "0     11.423593      1  \n",
              "1     17.811756      1  \n",
              "2     14.082993      1  \n",
              "3     11.848842      1  \n",
              "4     13.823575      1  \n",
              "...         ...    ...  \n",
              "1918  37.664210      1  \n",
              "1919  12.912899      1  \n",
              "1920  22.873760      1  \n",
              "1921  24.101467      1  \n",
              "1922  23.699362      1  \n",
              "\n",
              "[1923 rows x 7 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3C8uiEKXPS3"
      },
      "outputs": [],
      "source": [
        "df_edge_feature =  pd.read_csv(\"/content/drive/MyDrive/edge_features.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fA0zuCe4XPVb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"/content/drive/MyDrive/orca_count_dictionary_ver1.json\") as f:\n",
        "    json_data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jxhsvm_XPXm"
      },
      "outputs": [],
      "source": [
        "node_features_df = pd.DataFrame(json_data).transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjfC7k6C-43t"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Pxn10uJXPbJ",
        "outputId": "db3db354-9395-4b65-80d7-be541ea65bba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-d7f24230fd0d>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  edge_labels=torch.tensor(edge_labels).float()\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GCNConv\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "edge_features_df = pd.read_csv(\"/content/drive/MyDrive/edge_features.csv\",usecols=[\"MinimumDistance\"])\n",
        "edge_index_df = pd.read_csv('/content/drive/MyDrive/Proteins_for_MCODE.csv', usecols=['Node1', 'Node2'])\n",
        "\n",
        "node_features = torch.tensor(node_features_df.values, dtype=torch.float32)\n",
        "edge_features = torch.tensor(edge_features_df.values, dtype=torch.float32)\n",
        "\n",
        "edge_index = torch.tensor(edge_index_df.values, dtype=torch.long).t().contiguous()\n",
        "num_nodes = len(node_features)\n",
        "\n",
        "\n",
        "node_labels = torch.ones(edge_index.size(1))\n",
        "edge_labels = torch.ones(edge_index.size(1))\n",
        "edge_labels=torch.tensor(edge_labels).float()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AlEH0OAoKIA",
        "outputId": "c29be6b6-1951-4414-8826-fddd83eade9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1.,  ..., 1., 1., 1.])\n"
          ]
        }
      ],
      "source": [
        "data = Data(\n",
        "    x=node_features,\n",
        "    edge_index=edge_index,\n",
        "    y=node_labels,\n",
        "    edge_attr=edge_features,\n",
        "    edge_labels=edge_labels\n",
        ")\n",
        "\n",
        "print(data.edge_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auAT4yCToNnE"
      },
      "outputs": [],
      "source": [
        "import torch_geometric.transforms as T\n",
        "transform = T.RandomLinkSplit(\n",
        "    num_val=0.1,\n",
        "    num_test=0.1,\n",
        "    #disjoint_train_ratio=0.3,\n",
        "    neg_sampling_ratio=1.0,\n",
        "    add_negative_train_samples=True,\n",
        ")\n",
        "train_data, val_data, test_data = transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RxckaO6odsj"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "def adj_func(datas):\n",
        "\n",
        "    sc = StandardScaler()\n",
        "\n",
        "    lst1 = [int(a) for a in datas.edge_index[0]]\n",
        "    lst2 = [int(b) for b in datas.edge_index[1]]\n",
        "\n",
        "    tensor1 = np.array([lst1])\n",
        "    tensor2 = np.array([lst2])\n",
        "\n",
        "    max_index = max(np.max(tensor1), np.max(tensor2))+1\n",
        "\n",
        "    adj_matrix = np.zeros((3084,3084), dtype=float)\n",
        "\n",
        "\n",
        "\n",
        "    data_val = sc.fit_transform(datas.edge_attr)\n",
        "\n",
        "    for i in range(len(datas.edge_index[0])):\n",
        "        adj_matrix[datas.edge_index[0][i],datas.edge_index[1][i]] = data_val[i][0]\n",
        "\n",
        "\n",
        "    return adj_matrix,max_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9G4RFix68fA"
      },
      "outputs": [],
      "source": [
        "# complex data with positive combinations\n",
        "\n",
        "lst_all = []\n",
        "for val in json_datas.values():\n",
        "  lst = []\n",
        "  for j in val[1][0]:\n",
        "    filt = df[\"String\"] == j\n",
        "    lst.append(list(df[filt].Number)[0])\n",
        "  lst_all.append(lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7qcCGjo4klo",
        "outputId": "70738e54-7233-4069-b7c9-891ea0b36baf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[15, 16, 2662], [1219, 1218, 2727], [590, 2415, 789], [2001, 1441, 1456], [683, 685, 2701], [3054, 2294, 711], [1803, 2399, 273], [2450, 1219, 524], [1325, 781, 780], [2167, 1805, 524], [590, 2415, 1369], [1803, 2399, 1805], [1803, 2399, 1805], [758, 1282, 1104], [758, 1282, 1110], [1703, 1295, 2692], [2458, 1191, 579], [988, 1001, 1554], [988, 1001, 1554], [513, 1072, 1427], [513, 1072, 2301], [974, 586, 1318], [1594, 1422, 2320], [1462, 1495, 1463], [1264, 1302, 1832], [1264, 1302, 1832], [42, 41, 15], [2451, 1805, 2449], [1505, 1170, 169], [1505, 1466, 210], [1847, 1805, 1558], [169, 124, 170], [3054, 2294, 711], [1585, 2450, 1240], [1585, 2450, 14], [279, 280, 288], [2059, 2293, 2323], [2859, 2879, 2861], [800, 1007, 817], [2343, 178, 2548], [689, 586, 1318], [1027, 2, 48], [1219, 1218, 2727], [1219, 40, 1218], [758, 1282, 1110], [758, 1282, 1104], [758, 1282, 1104], [758, 1282, 1110], [1219, 1218, 2727], [988, 1001, 1554], [2507, 681, 783], [1102, 2266, 1166], [974, 689, 712], [542, 541, 828], [2507, 783, 639], [2507, 783, 639], [683, 2507, 685], [2507, 783, 639], [988, 428, 1001], [1056, 513, 1250], [1292, 1291, 1869], [1292, 1291, 1869], [1292, 1291, 1869], [1292, 1291, 1869], [1292, 1291, 1869], [513, 1292, 1291], [1703, 1295, 1294], [1703, 1295, 1294], [513, 514, 1235], [1215, 1198, 566], [513, 1250, 1235], [513, 2180, 1235], [513, 1263, 1235], [513, 1256, 1235], [1072, 1427, 514], [1072, 514, 1142], [1703, 1295, 1288], [1703, 1288, 1087], [2758, 1703, 1295], [1703, 1295, 1288], [974, 689, 428], [2178, 530, 535], [2178, 2164, 979], [604, 978, 1273], [3036, 252, 1888], [2178, 530, 535], [2458, 1191, 579], [2458, 1191, 579], [2458, 1191, 1192], [1350, 554, 1351], [1350, 554, 1351], [1350, 554, 1351], [1350, 554, 1351], [554, 1351, 1353], [554, 1351, 1353], [554, 1351, 1353], [1528, 1613, 1526], [758, 2450, 1803], [2167, 1805, 524], [1703, 1295, 1288], [269, 1011, 1013], [1703, 1295, 1288], [1703, 1295, 1288], [269, 1011, 1013], [269, 604, 1011], [604, 1011, 603], [483, 2038, 852], [1703, 1295, 1288], [1703, 1295, 1288], [689, 18, 2078], [689, 1712, 2532], [2495, 2892, 2684], [2495, 2892, 264], [264, 649, 2536], [130, 269, 252], [269, 140, 142], [143, 269, 140], [269, 140, 962], [2095, 2096, 885], [2091, 2095, 2650], [534, 986, 533], [2091, 2650, 2092], [988, 1001, 1554], [2495, 2892, 2846], [628, 791, 1523], [534, 986, 533], [534, 986, 533], [534, 986, 533], [1069, 1070, 1071], [574, 1011, 1502], [604, 1011, 1013], [604, 1011, 1013], [269, 604, 1011], [269, 1011, 1013], [964, 1825, 610], [839, 838, 837], [1072, 514, 1075], [513, 1263, 1090], [604, 603, 2514], [604, 603, 2514], [269, 604, 2514], [1523, 798, 953], [604, 1011, 1013], [988, 554, 1351], [554, 1351, 428], [554, 1351, 428], [428, 1013, 1554], [706, 705, 428], [1703, 1295, 424], [565, 681, 124], [1027, 706, 705], [1027, 706, 705], [1027, 706, 705], [1027, 706, 705], [1027, 2, 48], [1027, 2, 48], [1027, 706, 705], [707, 706, 705], [706, 705, 60], [706, 705, 60], [707, 706, 705], [706, 47, 704], [1027, 2, 48], [1027, 2, 48], [516, 2003, 68], [1027, 2, 48], [1027, 2, 48], [1027, 2, 48], [1027, 2, 48], [1027, 706, 705], [1027, 2, 48], [241, 153, 463], [241, 1004, 636], [180, 193, 2360], [180, 193, 2360], [689, 441, 709], [689, 441, 887], [689, 2532, 441], [574, 536, 1502], [1703, 1295, 1288], [1703, 1295, 1288], [1703, 1295, 1288], [1703, 1295, 1288], [1194, 1279, 1933], [448, 158, 217], [1742, 944, 849], [689, 586, 663], [974, 689, 586], [689, 586, 663], [753, 1029, 950], [974, 689, 712], [689, 586, 663], [974, 689, 586], [974, 586, 15], [974, 15, 16], [164, 606, 605], [42, 432, 2298], [2399, 273, 524], [2399, 1805, 2277], [1805, 524, 1316], [1805, 524, 1316], [1805, 524, 1316], [1106, 1805, 1692], [1072, 1427, 514], [988, 1001, 1554], [988, 1001, 1007], [1106, 524, 966], [1056, 1250, 1292], [1106, 583, 524], [988, 1001, 1554], [1106, 1803, 589], [1106, 589, 524], [1106, 589, 524], [1106, 524, 966], [1585, 1106, 3046], [1106, 3046, 583], [1106, 1803, 2399], [1106, 524, 1105], [1803, 2399, 1805], [1803, 2399, 1805], [736, 735, 737], [736, 75, 735], [1803, 2399, 1805], [2724, 153, 2332], [983, 982, 2142], [1803, 2399, 1805], [983, 2724, 982], [2167, 1805, 524], [1805, 524, 1316], [1805, 524, 1316], [1805, 524, 1316], [1163, 1936, 2899], [974, 1193, 689], [974, 1193, 689], [974, 1193, 689], [974, 1193, 689], [13, 524, 2601], [2917, 2019, 728], [1812, 513, 1811], [1812, 513, 1811], [715, 1812, 513], [513, 1072, 514], [2167, 1805, 524], [2167, 1805, 524], [2167, 974, 689], [1076, 996, 997], [590, 2415, 789], [1383, 1385, 1386], [2167, 1805, 524], [1076, 996, 997], [966, 2601, 274], [524, 2601, 274], [3028, 524, 966], [590, 2415, 274], [1153, 104, 423], [1076, 996, 997], [1076, 996, 997], [2167, 1755, 2168], [1076, 996, 997], [1755, 1335, 948], [974, 1803, 2399], [210, 1072, 1427], [996, 997, 1755], [689, 441, 721], [2389, 873, 872], [2389, 873, 872], [1937, 1936, 2547], [689, 441, 887], [689, 2532, 3023], [974, 1193, 689], [974, 1193, 689], [974, 1193, 689], [974, 1193, 689], [1193, 1509, 116], [1193, 1509, 116], [880, 1541, 949], [880, 948, 949], [1755, 880, 948], [1193, 1614, 1499], [2356, 950, 2357], [1184, 953, 952], [1193, 953, 1614], [1641, 193, 1220], [1742, 1721, 267], [1641, 1220, 2870], [1193, 1184, 953], [1614, 1499, 1156], [1193, 953, 1614], [953, 1614, 1157], [1193, 1614, 1508], [1826, 2875, 2895], [269, 1657, 1374], [2758, 548, 1623], [1106, 550, 524], [2432, 2430, 2900], [2898, 2430, 2900], [2432, 2900, 2457], [2898, 2432, 2430], [1562, 241, 153], [2399, 1805, 2277], [1803, 2399, 1805], [1805, 2277, 1316], [1087, 1088, 1667], [1087, 1088, 1667], [1703, 1288, 1087], [1703, 1288, 1667], [2225, 1220, 2870], [1703, 1288, 1294], [1703, 1295, 1288], [2451, 1805, 2449], [917, 1839, 1747], [2450, 2957, 1414], [225, 183, 1774], [988, 428, 1001], [988, 1001, 1554], [1847, 1805, 1558], [139, 142, 554], [40, 1116, 530], [130, 40, 1116], [169, 124, 170], [169, 124, 170], [169, 439, 470], [839, 838, 837], [838, 836, 963], [839, 838, 837], [839, 838, 836], [169, 124, 170], [124, 170, 171], [839, 838, 837], [1245, 1539, 415], [513, 1072, 1427], [513, 1072, 514], [424, 206, 1346], [736, 75, 735], [75, 735, 737], [953, 1157, 1500], [988, 1001, 1554], [1093, 2518, 1094], [2488, 467, 75], [269, 534, 986], [2488, 7, 75], [2488, 74, 75], [2488, 340, 75], [1383, 1385, 1386], [1116, 1839, 269], [1116, 1839, 269], [2015, 2012, 2013], [2015, 2012, 2013], [1116, 2015, 2012], [269, 2018, 1419], [269, 552, 2018], [1116, 1839, 269], [2015, 2012, 2013], [3068, 2, 2015], [1245, 1093, 1094], [1093, 1107, 1094], [1093, 1107, 1094], [1093, 1107, 1108], [1411, 1691, 966], [1937, 1936, 2547], [1937, 1936, 2547], [1939, 124, 3043], [1184, 953, 1157], [1184, 953, 1157], [1606, 1642, 1650], [1608, 1642, 1649], [795, 1904, 3043], [1778, 1827, 1194], [1778, 1827, 761], [2178, 2164, 2429], [1519, 1527, 1521], [550, 939, 1521], [715, 1509, 1519], [269, 15, 561], [513, 1263, 1256], [689, 1318, 887], [1607, 1643, 1647], [689, 701, 709], [689, 701, 709], [689, 709, 895], [1245, 1015, 415], [1847, 995, 863], [1414, 1072, 1927], [2820, 2268, 798], [1414, 2169, 2943], [2275, 798, 795], [1544, 1543, 1330], [590, 2415, 274], [988, 534, 986], [718, 211, 715], [40, 534, 986], [2440, 235, 1927], [800, 1007, 817], [1007, 817, 799], [800, 817, 799], [2700, 800, 799], [800, 1007, 1554], [2700, 800, 1007], [1007, 799, 816], [1309, 195, 513], [513, 1263, 1090], [513, 1072, 514], [2700, 800, 2972], [534, 986, 1007], [858, 1215, 2957], [1215, 40, 2957], [1215, 2957, 990], [974, 689, 1183], [1193, 634, 2103], [2407, 2601, 1105], [974, 689, 712], [689, 586, 663], [689, 586, 663], [974, 689, 712], [974, 689, 586], [513, 1072, 514], [575, 1509, 1261], [2415, 1072, 2852], [575, 2352, 1261], [2167, 2450, 1106], [513, 1072, 1073], [1805, 1280, 763], [513, 1072, 514], [793, 82, 1947], [1414, 975, 938], [2, 48, 2443], [2, 51, 2443], [628, 1523, 1904], [2774, 2102, 2590], [1096, 2309, 1043], [1, 18, 1126], [609, 2886, 2887], [1564, 752, 987], [1286, 1261, 1262], [1286, 2590, 1564], [1286, 2390, 48], [590, 789, 586], [678, 965, 1708], [1240, 1927, 1242], [1017, 10, 15], [10, 107, 567], [134, 851, 2424], [1, 1657, 163], [1106, 524, 966], [1803, 2399, 1805], [590, 789, 524], [286, 287, 203], [156, 2038, 912], [2038, 15, 1795], [9, 1310, 2364], [787, 786, 1097], [2640, 415, 510], [534, 986, 533], [1310, 165, 1867], [1310, 165, 2716], [1254, 1310, 165], [2178, 2164, 2185], [2178, 2164, 2429], [2178, 2164, 2429], [143, 140, 145], [143, 140, 240], [143, 146, 464], [232, 142, 980], [139, 134, 532], [65, 67, 66], [201, 200, 202], [1266, 2668, 1683], [627, 1955, 1215], [1215, 40, 211], [83, 2824, 750], [798, 708, 2633], [1157, 1500, 1501], [1184, 795, 953], [1184, 1717, 1499], [1184, 953, 2], [1184, 795, 953], [1184, 952, 1154], [1116, 3043, 908], [1939, 715, 1940], [1939, 715, 2460], [1939, 715, 1940], [1794, 417, 406], [417, 406, 2870], [1794, 417, 2045], [328, 327, 1532], [147, 19, 193], [180, 851, 2478], [973, 851, 850], [1151, 417, 851], [851, 15, 425], [1061, 1212, 972], [758, 1282, 1284], [1936, 2900, 2899], [115, 1236, 2155], [43, 1128, 1299], [43, 1128, 1299], [43, 1298, 1299], [316, 317, 476], [317, 476, 445], [316, 317, 445], [856, 72, 991], [613, 612, 856], [164, 576, 602], [164, 576, 602], [613, 612, 633], [613, 612, 609], [196, 728, 597], [613, 612, 625], [613, 612, 625], [612, 424, 1346], [2225, 652, 1092], [1549, 513, 514], [513, 1263, 1090], [1812, 1811, 1807], [42, 1812, 1811], [590, 2415, 789], [513, 1072, 514], [513, 1072, 851], [513, 1072, 514], [513, 1072, 514], [554, 1351, 1353], [554, 1351, 1353], [269, 554, 1351], [554, 1351, 1353], [1669, 554, 1351], [940, 837, 710], [1608, 428, 1649], [715, 428, 429], [428, 1793, 1687], [428, 1793, 582], [988, 1001, 22], [988, 1001, 989], [574, 218, 1502], [530, 535, 529], [42, 1011, 1013], [579, 578, 978], [1805, 1280, 763], [761, 1279, 1280], [1084, 1827, 1279], [1881, 2585, 1119], [1233, 1318, 3011], [1414, 1318, 2061], [418, 1026, 2071], [1743, 993, 1953], [1026, 1882, 1953], [1026, 407, 1953], [191, 1026, 2833], [191, 1026, 2833], [191, 1026, 1882], [191, 1026, 1489], [74, 191, 1026], [191, 190, 259], [191, 1026, 1882], [1743, 191, 190], [191, 190, 138], [191, 190, 1734], [1743, 125, 1484], [125, 259, 433], [125, 1736, 434], [125, 2026, 2360], [125, 2087, 2833], [125, 1736, 2087], [125, 133, 2833], [74, 1172, 745], [74, 4, 1171], [451, 4, 1171], [424, 138, 6], [138, 912, 1200], [340, 5, 1627], [4, 6, 5], [516, 68, 2177], [516, 68, 1627], [759, 86, 189], [4, 87, 1139], [4, 92, 87], [135, 87, 1139], [74, 4, 87], [759, 189, 1014], [340, 189, 6], [993, 135, 314], [993, 1000, 135], [64, 993, 135], [7, 6, 88], [1093, 1094, 1108], [1058, 1093, 253], [1093, 1107, 1094], [1338, 432, 863], [1528, 1613, 1526], [884, 211, 715], [1703, 884, 1669], [884, 1669, 720], [884, 1406, 720], [718, 884, 720], [884, 720, 1427], [884, 2233, 720], [1288, 40, 1088], [1288, 1087, 1088], [715, 439, 1006], [884, 715, 888], [11, 16, 2662], [701, 404, 1537], [701, 235, 704], [424, 439, 470], [169, 439, 470], [424, 42, 41], [1505, 1170, 1466], [1505, 1466, 210], [227, 147, 851], [227, 147, 1596], [227, 147, 1781], [227, 147, 2926], [1979, 851, 2424], [54, 851, 2424], [853, 851, 2424], [147, 851, 2424], [213, 910, 2548], [513, 1072, 1811], [609, 2886, 2887], [539, 225, 183], [225, 183, 1774], [2390, 2317, 196], [513, 1263, 1090], [207, 1072, 514], [207, 1072, 514], [613, 612, 440], [440, 1202, 16], [1261, 1262, 2456], [2390, 1261, 1262], [530, 535, 529], [2178, 535, 978], [856, 1181, 666], [856, 1179, 2330], [1248, 856, 1179], [1249, 2228, 851], [1523, 798, 82], [953, 1157, 1500], [665, 664, 666], [853, 851, 2424], [851, 1338, 2424], [534, 986, 1001], [988, 1001, 1554], [1072, 514, 2718], [1072, 514, 2676], [990, 431, 989], [431, 989, 1282], [1608, 428, 429], [428, 820, 893], [428, 893, 582], [565, 428, 429], [1825, 678, 1708], [1825, 678, 965], [269, 554, 1351], [554, 1351, 1353], [554, 1351, 1353], [1350, 554, 1351], [428, 524, 966], [565, 988, 428], [565, 428, 604], [428, 550, 429], [428, 583, 582], [428, 734, 429], [428, 469, 429], [1505, 1170, 169], [586, 851, 2424], [851, 850, 2122], [851, 2424, 850], [1372, 1414, 1268], [1193, 1614, 1508], [1151, 42, 2298], [1151, 42, 2298], [191, 1026, 1736], [1743, 125, 1484], [56, 1805, 524], [689, 663, 661], [689, 441, 887], [689, 441, 887], [191, 190, 259], [884, 1406, 720], [884, 1669, 720], [884, 1669, 720], [884, 1406, 720], [1072, 514, 608], [513, 1072, 514], [125, 1026, 1882], [888, 1006, 889], [191, 190, 2833], [888, 1006, 889], [1006, 2971, 274], [534, 986, 14], [3046, 583, 2468], [759, 189, 6], [583, 2468, 582], [1006, 2468, 582], [1006, 583, 2468], [64, 6, 888], [14, 888, 1006], [759, 64, 189], [759, 189, 4], [189, 1140, 1139], [86, 189, 1139], [5, 2023, 2046], [43, 1128, 1299], [43, 1298, 1299], [134, 851, 107], [43, 1298, 1299], [1794, 417, 406], [1151, 193, 245], [1151, 1061, 193], [1935, 1061, 972], [1027, 2, 48], [1027, 51, 2443], [1061, 972, 770], [1061, 972, 943], [232, 142, 980], [418, 417, 406], [407, 417, 406], [418, 417, 406], [728, 1080, 752], [141, 513, 1072], [2497, 1548, 2496], [361, 364, 360], [789, 2248, 524], [3, 81, 164], [1805, 524, 1316], [524, 966, 2601], [929, 966, 2601], [1215, 778, 1116], [1087, 715, 116], [1087, 715, 1088], [715, 663, 16], [974, 1193, 689], [2, 1087, 715], [689, 1087, 1088], [124, 1087, 715], [1087, 116, 1088], [554, 1351, 1353], [1286, 1567, 1261], [2957, 1904, 211], [2178, 2164, 2185], [534, 986, 879], [125, 1484, 1882], [888, 1006, 889], [1184, 953, 1157], [2647, 1747, 819], [1215, 40, 211], [40, 138, 715], [40, 138, 715], [2118, 1805, 524], [1006, 524, 274], [1151, 1061, 193], [524, 966, 2601], [1151, 42, 671], [42, 1888, 41], [2248, 2247, 2424], [789, 2248, 850], [789, 2248, 851], [789, 2248, 2424], [2424, 524, 850], [524, 2601, 274], [1, 586, 524], [1184, 952, 1137], [534, 990, 1747], [2248, 2424, 850], [2248, 851, 2424], [2424, 850, 16], [851, 2424, 16], [2248, 851, 2424], [2248, 851, 524], [2247, 851, 1100], [43, 1128, 2524], [43, 1298, 1299], [1309, 1308, 625], [513, 1072, 514], [534, 986, 1503], [947, 946, 1223], [947, 946, 1223], [947, 946, 1223], [1821, 946, 1223], [947, 1821, 946], [1562, 241, 153], [1268, 1438, 1391], [143, 962, 145], [143, 962, 240], [1017, 1657, 10], [1017, 10, 15], [139, 134, 163], [232, 134, 532], [74, 1172, 1171], [534, 986, 533], [180, 138, 2755], [40, 534, 986], [534, 986, 533], [1112, 534, 986], [712, 3028, 524], [595, 627, 612], [613, 680, 612], [1567, 1261, 1564], [594, 623, 612], [988, 1001, 978], [238, 237, 16], [196, 728, 651], [782, 468, 1787], [512, 506, 640], [9, 787, 1801], [196, 728, 512], [612, 206, 614], [225, 183, 1774], [606, 2466, 206], [530, 535, 529], [595, 612, 164], [534, 986, 530], [628, 612, 164], [613, 612, 679], [613, 196, 728], [40, 534, 986], [838, 534, 986], [934, 861, 938], [19, 193, 738], [19, 193, 15], [19, 193, 16], [613, 612, 196], [1056, 1292, 1291], [665, 196, 728], [196, 728, 644], [1056, 1292, 1291], [681, 1056, 852], [1393, 852, 1199], [612, 728, 644], [612, 196, 728], [42, 534, 429], [2926, 586, 663], [42, 14, 41], [770, 2046, 1482], [5, 2046, 1482], [1264, 1302, 2890], [715, 116, 63], [1080, 752, 987], [2562, 1080, 1911], [2562, 1911, 987], [1080, 752, 987], [1027, 2440, 48], [428, 550, 216], [1841, 205, 1891], [758, 1282, 1284], [1755, 1335, 998], [2758, 1703, 1295], [164, 206, 1202], [164, 207, 206], [595, 206, 204], [206, 204, 592], [207, 206, 204], [73, 72, 991], [164, 207, 206], [1847, 14, 995], [1585, 1240, 2242], [32, 512, 2812], [512, 72, 31], [130, 269, 252], [562, 130, 269], [558, 130, 269], [130, 252, 2345], [130, 252, 1247], [130, 139, 142], [155, 156, 1793], [350, 349, 156], [352, 156, 351], [10, 1805, 532], [2003, 1317, 1318], [1955, 1950, 1317], [590, 134, 1317], [1955, 1, 1950], [858, 1950, 8], [2167, 590, 1950], [2692, 3069, 2385], [993, 1147, 1146], [1268, 2467, 1270], [1657, 524, 1375], [196, 1153, 848], [4, 1171, 2780], [4, 1171, 2788], [417, 406, 851], [2, 715, 1318], [659, 981, 991], [738, 1022, 1021], [1641, 193, 774], [659, 72, 991], [659, 73, 72], [73, 72, 991], [1201, 916, 2509], [656, 657, 833], [1841, 1476, 803], [613, 612, 625], [728, 597, 1849], [73, 72, 991], [73, 72, 991], [424, 1840, 423], [93, 2688, 251], [9, 2688, 251], [787, 2726, 861], [9, 93, 2688], [9, 93, 100], [9, 251, 2923], [93, 251, 2923], [728, 1849, 859], [72, 991, 1849], [1841, 74, 2771], [860, 1414, 771], [2559, 1216, 2586], [1995, 1414, 859], [954, 1187, 955], [2161, 2162, 2176], [884, 1783, 720], [41, 732, 671], [996, 1015, 946], [132, 162, 131], [511, 2326, 415], [1194, 1279, 551], [2285, 2283, 2291], [5, 2023, 943], [2285, 2283, 2284], [1462, 1495, 1463], [74, 138, 1200], [1956, 1957, 1958], [1058, 1094, 1108], [1965, 728, 2763], [191, 1026, 2071], [2450, 798, 174], [3031, 3033, 3032], [1422, 3017, 3018], [3031, 1422, 3033], [715, 1644, 1972], [1125, 598, 1124], [2470, 2485, 2419], [2470, 2485, 2419], [2230, 2871, 1889], [1780, 2289, 2446], [2059, 2323, 2305], [245, 626, 359], [424, 91, 92], [132, 162, 131], [965, 1194, 1279], [1292, 1291, 1869], [2697, 848, 2595], [1263, 1090, 1142], [42, 130, 240], [2450, 798, 174], [758, 1282, 757], [33, 1121, 1144], [33, 1143, 1144], [33, 2567, 1144], [609, 2886, 2887], [2594, 193, 1826], [1286, 1262, 1569], [1489, 942, 1206], [1151, 193, 1188], [613, 612, 665], [1657, 1931, 2120], [277, 32, 512], [1151, 245, 2394], [1151, 1061, 193], [193, 1877, 15], [1062, 462, 463], [1253, 1252, 1251], [72, 76, 991], [1672, 1674, 1625], [134, 10, 524], [1261, 1277, 1262], [2854, 2434, 2853], [575, 1286, 2317], [1567, 1261, 1564], [575, 2317, 2352], [2854, 2434, 2855], [1286, 1567, 1261], [1431, 1432, 1450], [2390, 2317, 2352], [2317, 2352, 1261], [29, 1244, 62], [1812, 1811, 1256], [1056, 1292, 1291], [1847, 1263, 1090], [1261, 1263, 1090], [1263, 1262, 1090], [1263, 1090, 1651], [1014, 2055, 2266], [424, 15, 1202], [2628, 1324, 511], [196, 1599, 597], [1540, 1119, 1757], [1817, 848, 2604], [1341, 2930, 2929], [2118, 1263, 1090], [2752, 1256, 1090], [2743, 2744, 2746], [2022, 2301, 2295], [2022, 42, 513], [1641, 342, 774], [142, 163, 107], [21, 2023, 2266], [2360, 2291, 2284], [2252, 2253, 2300], [2022, 2301, 2295], [2252, 2253, 2300], [60, 704, 703], [706, 705, 167], [707, 1261, 704], [706, 705, 60], [665, 707, 1261], [545, 868, 2740], [996, 997, 948], [1422, 3033, 3032], [1093, 253, 1094], [1253, 1252, 1445], [942, 1206, 2520], [942, 1206, 2520], [983, 74, 2128], [154, 2361, 1324], [154, 1324, 246], [154, 1324, 246], [154, 1324, 246], [89, 91, 1531], [2470, 2485, 1592], [513, 1072, 514], [234, 233, 2017], [2268, 2839, 1617], [64, 2235, 6], [1261, 1262, 1278], [1261, 1262, 1570], [1261, 1262, 1278], [1261, 1277, 1262], [1193, 1051, 1052], [1193, 2286, 1966], [2957, 2922, 1393], [197, 435, 1374], [197, 435, 2121], [2659, 1682, 1415], [513, 1263, 1090], [2178, 2164, 2429], [1393, 1357, 1391], [1151, 2797, 2874], [2881, 2863, 2862], [513, 1072, 514], [513, 1072, 514], [513, 1072, 514], [513, 1072, 514], [78, 1205, 1272], [191, 315, 323], [701, 704, 703], [1324, 246, 1489], [428, 216, 429], [125, 1717, 434], [743, 1919, 744], [1610, 2503, 2504], [1610, 2506, 2504], [1610, 2505, 2504], [1610, 2503, 2506], [1610, 2503, 2505], [2635, 1318, 1975], [191, 315, 1026], [197, 880, 951], [246, 1323, 912], [222, 158, 217], [427, 738, 215], [923, 924, 1145], [2470, 2485, 2419], [2470, 2485, 2419], [1400, 810, 120], [1400, 418, 810], [2480, 241, 245], [2379, 1151, 245], [1253, 1252, 1445], [1253, 1252, 1445], [1253, 1252, 1445], [1253, 1252, 1445], [534, 986, 533], [2317, 2352, 1261], [1803, 1691, 2627], [1058, 65, 9], [727, 2882, 704], [196, 2374, 245], [1406, 534, 986], [574, 536, 535], [2635, 1318, 2103], [1847, 1558, 995], [2599, 2603, 2718], [1051, 15, 2298], [2317, 2352, 1819], [1728, 1748, 1729], [2157, 1261, 1262], [513, 2180, 1201], [974, 1193, 689], [712, 586, 1558], [1655, 1508, 1656], [1558, 995, 1656], [1193, 712, 586], [993, 189, 714], [1715, 1775, 1194], [1775, 1194, 1776], [42, 2336, 732], [1486, 1434, 1433], [2389, 2637, 873], [2225, 1220, 2870], [842, 2559, 1971], [590, 789, 274], [1991, 260, 1324], [114, 1067, 2400], [193, 432, 903], [1304, 1306, 1305], [2859, 2879, 1474], [883, 1404, 1405], [513, 1250, 1292], [1770, 2080, 972], [884, 1406, 720], [1056, 1292, 1291], [2343, 178, 441], [1703, 1295, 1288], [1703, 1295, 1288], [1087, 1088, 1293], [1087, 1088, 1293]]\n"
          ]
        }
      ],
      "source": [
        "print(lst_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "km5IG0zrz6Ws"
      },
      "outputs": [],
      "source": [
        "# complex data with negative combinations\n",
        "\n",
        "lst_all_neg = []\n",
        "for val in neg_json_datas.values():\n",
        "  lst_neg = []\n",
        "  for k in val:\n",
        "    filt = df[\"String\"] == k\n",
        "    lst_neg.append(list(df[filt].Number)[0])\n",
        "  lst_all_neg.append(lst_neg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z3oWKrh0RA3",
        "outputId": "51a2364c-d498-41fe-8af8-098cfbef0136"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[213, 2403, 167], [2275, 2369, 2307], [2402, 2676, 2697], [899, 3011, 1801], [2716, 3022, 2763], [364, 2740, 1531], [1411, 2531, 213], [2558, 2509, 2740], [1097, 2567, 2235], [1411, 3011, 2674], [2972, 1867, 1718], [2880, 2332, 1734], [3024, 2228, 2336], [2880, 2749, 1097], [1198, 2142, 1711], [483, 2357, 1718], [2972, 2228, 2647], [2055, 342, 2150], [2568, 1919, 2762], [899, 2647, 2780], [2182, 2567, 2336], [2716, 2326, 167], [1718, 167, 2150], [2228, 2755, 2235], [2880, 1043, 1531], [2972, 2228, 2336], [2749, 1616, 2922], [1390, 1935, 2150], [3022, 2763, 1919], [2518, 1112, 2697], [899, 2647, 2055], [2676, 2755, 2637], [2640, 2055, 924], [2320, 2019, 2716], [1043, 2567, 924], [2142, 2487, 1718], [2275, 2136, 1718], [2142, 1935, 2762], [2326, 1341, 1531], [2019, 3011, 2150], [2880, 467, 2487], [2518, 2567, 2762], [1325, 1933, 1711], [1325, 1198, 3011], [2972, 1867, 1341], [1734, 213, 2659], [2142, 2749, 2763], [2640, 1801, 1476], [2518, 1935, 2307], [3024, 467, 2402], [1097, 2676, 2307], [1718, 2326, 2674], [1325, 1616, 3022], [2668, 167, 2307], [2852, 1711, 727], [1734, 2377, 2055], [2275, 2369, 2676], [2880, 2136, 1935], [2716, 342, 2659], [2357, 2676, 2740], [1933, 2403, 342], [2763, 2235, 2150], [1390, 1935, 1599], [3024, 2558, 2972], [2852, 2487, 1476], [2972, 1867, 364], [2880, 2755, 1341], [1411, 1734, 2487], [25, 1891, 2922], [2558, 2019, 2326], [2558, 2749, 2235], [2509, 2740, 2637], [2640, 2668, 167], [2749, 2972, 2182], [2640, 2771, 2307], [213, 2659, 2157], [1198, 2487, 2740], [1734, 2659, 2157], [1734, 25, 2509], [1411, 1867, 2676], [2228, 1112, 2377], [213, 2228, 2726], [2320, 2357, 1919], [2487, 2740, 2361], [3024, 1711, 2361], [1718, 924, 2157], [1325, 3024, 2487], [1325, 2142, 2377], [1933, 2852, 2752], [2142, 364, 2568], [1867, 1801, 2361], [1891, 2326, 2752], [1933, 2647, 2361], [1325, 2716, 167], [1043, 1867, 1711], [1325, 2228, 2762], [2780, 2235, 2922], [1711, 213, 25], [467, 1531, 1919], [483, 267, 2668], [1097, 1112, 2361], [2518, 1097, 1891], [1198, 1043, 2150], [2852, 2640, 213], [2055, 2752, 2157], [467, 2055, 2762], [2357, 1819, 1067], [2332, 2640, 2487], [2332, 2518, 2275], [2142, 1711, 213], [1616, 2509, 2763], [267, 1801, 2659], [1867, 25, 2726], [1933, 2509, 2740], [1781, 2755, 2771], [2357, 1867, 2676], [2142, 2568, 2235], [2332, 25, 2336], [2852, 2402, 3022], [2647, 2377, 2336], [1097, 2716, 1891], [1390, 467, 1411], [25, 2647, 2763], [2326, 2697, 2752], [267, 2275, 2326], [899, 2568, 2674], [2852, 1711, 364], [899, 1112, 2780], [2357, 1043, 2567], [2275, 2755, 2922], [3024, 2402, 1067], [2749, 2377, 1067], [3024, 1043, 2762], [2402, 1711, 167], [2369, 1801, 2752], [2880, 1112, 1819], [2320, 2568, 2157], [2142, 2357, 2336], [25, 2780, 2752], [1734, 2326, 1341], [1097, 2228, 1891], [3024, 2676, 2017], [2531, 1781, 2361], [267, 2403, 727], [2558, 1476, 2659], [2531, 2726, 2055], [2275, 213, 1891], [2749, 3011, 3022], [2142, 1711, 25], [1411, 2136, 1531], [1411, 2055, 2740], [2332, 364, 1801], [1933, 2726, 167], [2697, 2055, 2674], [467, 1867, 1711], [1411, 2228, 2568], [1718, 2336, 2150], [2518, 25, 2336], [2749, 2640, 2659], [2880, 1043, 2676], [1325, 1933, 1043], [1891, 2771, 924], [1734, 2676, 1919], [2531, 1112, 924], [2749, 467, 2275], [364, 2235, 2659], [2676, 1935, 2403], [2771, 2055, 1067], [2142, 2369, 2852], [2402, 2726, 2740], [1325, 2518, 2228], [2852, 1097, 1781], [2558, 467, 2361], [1097, 2377, 2674], [1097, 213, 3022], [1933, 2640, 3022], [1933, 2676, 2697], [2357, 213, 2017], [267, 2531, 167], [1801, 1341, 2336], [2320, 2780, 924], [899, 2716, 2726], [1711, 3011, 2182], [2357, 2640, 2377], [1734, 2762, 1819], [467, 924, 2157], [2142, 2749, 2055], [2558, 2403, 1531], [2771, 2763, 1531], [2668, 1112, 1476], [1043, 2361, 1919], [483, 2017, 2336], [2228, 1935, 2697], [1390, 1867, 2307], [2880, 1043, 727], [2142, 3022, 1919], [2780, 2017, 2922], [267, 2716, 2228], [1781, 1935, 2922], [2320, 2182, 342], [2676, 2755, 2752], [2880, 1891, 2697], [1390, 2275, 2780], [1198, 2640, 1476], [2402, 2716, 2740], [2531, 2780, 2752], [2019, 2763, 2637], [3024, 2275, 1616], [2668, 2377, 2307], [1933, 1781, 924], [2402, 1711, 2568], [2880, 1198, 2531], [2771, 2235, 2674], [3022, 2326, 2017], [2676, 2377, 1341], [2320, 2019, 2659], [2568, 2637, 1067], [2326, 2697, 2055], [2771, 2762, 2637], [2320, 3022, 2326], [1043, 2567, 2336], [2357, 2852, 727], [2136, 2369, 3022], [2275, 2136, 1599], [899, 1616, 727], [483, 213, 2487], [2019, 467, 167], [213, 2487, 727], [3024, 2377, 2361], [2518, 1891, 1819], [2402, 3011, 1599], [1411, 2275, 1476], [2019, 2668, 25], [2320, 2568, 2762], [2320, 467, 2150], [2019, 2369, 2055], [1411, 2235, 2659], [2332, 2676, 2017], [1198, 899, 1112], [2726, 2752, 2674], [2558, 267, 924], [2518, 1734, 2780], [2780, 2326, 2922], [2763, 2567, 924], [2509, 167, 1919], [2142, 2749, 2567], [25, 1341, 2150], [2275, 1935, 2637], [2332, 2369, 167], [1411, 2716, 924], [2136, 2740, 2157], [2880, 2518, 2716], [2852, 167, 2336], [1801, 2780, 2361], [1112, 2017, 1819], [2019, 2780, 2637], [1198, 899, 2182], [1198, 25, 364], [2716, 1935, 3022], [2763, 2336, 2674], [1935, 2326, 2697], [2320, 2377, 3022], [2558, 2332, 1341], [3022, 2697, 1919], [2357, 2307, 1067], [1781, 2509, 2307], [2647, 2377, 727], [1325, 899, 2531], [2716, 3011, 1919], [2640, 1867, 2763], [1043, 167, 1919], [2509, 1476, 2674], [2019, 2852, 2763], [2531, 1935, 2568], [2182, 3022, 2922], [1043, 1801, 1531], [1867, 1734, 2182], [1718, 1531, 2762], [2972, 1781, 364], [1043, 213, 1531], [2017, 2922, 727], [2755, 1891, 2509], [1734, 2182, 2567], [3022, 2780, 342], [2402, 2716, 342], [2668, 2567, 1531], [2726, 2326, 1819], [2972, 2676, 2403], [467, 2487, 2637], [1043, 25, 1819], [1198, 2668, 2487], [2019, 2716, 2674], [2361, 2922, 2637], [1891, 2697, 167], [2880, 167, 2740], [1390, 2509, 2017], [2357, 1734, 2771], [267, 2763, 2307], [2518, 2403, 1067], [2275, 1718, 2307], [3024, 2402, 2567], [1933, 1801, 2659], [1933, 2740, 2307], [2142, 267, 833], [3024, 2136, 727], [3024, 2676, 2568], [1781, 2752, 2740], [1390, 2361, 1919], [467, 1097, 2659], [2972, 2402, 2228], [1198, 2852, 2740], [1411, 2771, 924], [2647, 3022, 1476], [1867, 2403, 924], [2531, 2771, 2637], [1390, 1097, 833], [2228, 1891, 727], [1933, 2019, 2377], [2019, 213, 342], [267, 2531, 25], [2716, 2676, 1919], [2763, 167, 2235], [1112, 1531, 924], [1933, 3022, 1341], [2402, 2182, 2326], [2749, 25, 2568], [2567, 2055, 1341], [2275, 2755, 2674], [2668, 2361, 2307], [2142, 2726, 2674], [2402, 1616, 2361], [2275, 1599, 2740], [2880, 3011, 25], [2369, 2771, 2752], [2558, 2518, 2235], [2922, 2157, 2637], [2558, 2182, 2568], [483, 1734, 2647], [1198, 1390, 2922], [2357, 213, 1599], [2019, 25, 1919], [467, 2697, 2336], [2320, 2697, 2922], [1198, 2852, 3011], [2275, 1891, 2336], [2531, 25, 924], [2402, 1711, 1919], [2136, 1097, 1531], [2852, 2726, 2055], [1390, 2640, 1935], [3011, 1718, 2922], [2880, 2019, 2922], [899, 1819, 2637], [467, 1867, 2307], [1781, 1341, 1819], [2509, 2771, 1341], [3011, 3022, 727], [899, 2182, 1616], [1325, 2531, 2726], [2647, 1476, 2055], [1198, 364, 2740], [467, 2755, 1599], [2518, 213, 1935], [3011, 2403, 2055], [1411, 1341, 1531], [213, 3022, 2674], [483, 2716, 2509], [2142, 2568, 2336], [213, 2487, 2235], [2320, 1476, 2157], [1933, 1867, 727], [1411, 167, 727], [1616, 2326, 2637], [2752, 727, 2157], [2531, 364, 2647], [2880, 467, 2326], [899, 2568, 2762], [1867, 2659, 2762], [2518, 2567, 2922], [2019, 1097, 1891], [1390, 2357, 1341], [3022, 2509, 1531], [3024, 1935, 727], [3024, 2676, 2361], [2972, 2326, 2150], [1734, 2336, 2674], [1411, 2182, 213], [1097, 2676, 2567], [2755, 1801, 2637], [2716, 2755, 2017], [1198, 3024, 1599], [899, 1599, 1531], [2763, 2017, 2307], [2531, 2377, 2726], [1097, 2640, 727], [2763, 2017, 1919], [2275, 2716, 3022], [2235, 2922, 1919], [2136, 2640, 3022], [2369, 2763, 2922], [2676, 1531, 2637], [2369, 2228, 2740], [2487, 2055, 1531], [1325, 25, 1891], [2771, 1599, 2307], [467, 1935, 1919], [2697, 1531, 2762], [1198, 167, 1919], [267, 2235, 727], [1867, 2182, 1476], [267, 2726, 2763], [2676, 833, 1476], [2136, 2755, 2762], [899, 2055, 2752], [1097, 2668, 2674], [2320, 1781, 2752], [2019, 2640, 1891], [2019, 2780, 2762], [213, 2676, 924], [467, 1734, 2922], [2369, 2676, 2326], [167, 2336, 2637], [2402, 2640, 364], [2357, 2228, 2377], [1112, 2361, 2674], [1198, 1599, 167], [2136, 2972, 1781], [3024, 2136, 2017], [1043, 1734, 213], [2880, 2567, 342], [2716, 1891, 727], [2880, 2531, 2182], [1043, 2403, 2659], [2142, 2755, 2336], [2332, 1341, 2762], [1198, 2752, 924], [2531, 2509, 2307], [2332, 467, 2697], [2136, 364, 3022], [483, 2402, 1867], [899, 2332, 2509], [1933, 2326, 2697], [2749, 1599, 1819], [1390, 2676, 2726], [3024, 2668, 2228], [1325, 2136, 2055], [1781, 2487, 1341], [1198, 1935, 1531], [2332, 267, 1867], [2142, 213, 2674], [3011, 1801, 2568], [2531, 1935, 2326], [1933, 1711, 1891], [2716, 2567, 2055], [2357, 2182, 1599], [2668, 3011, 1476], [2531, 2716, 2487], [2332, 2142, 1935], [1411, 2055, 2307], [2531, 2326, 2697], [1801, 2509, 727], [899, 1616, 2235], [1781, 2676, 1819], [213, 2780, 2567], [2142, 833, 2674], [899, 2136, 1734], [2142, 2402, 2228], [1476, 2763, 2922], [2972, 2726, 2762], [2558, 267, 2275], [364, 2487, 1718], [2357, 2518, 1043], [2320, 1933, 1531], [2142, 1097, 1067], [2019, 1043, 2674], [899, 2668, 2017], [3011, 2377, 1891], [1198, 2771, 2235], [1112, 1476, 2763], [2275, 1867, 2361], [1411, 2228, 1935], [1411, 1867, 2637], [3011, 2726, 2659], [899, 2357, 1043], [1097, 2659, 1819], [2531, 1711, 2509], [3024, 2558, 25], [1711, 1734, 1112], [467, 2676, 2017], [1933, 2377, 2922], [2518, 2326, 1341], [483, 2326, 342], [2531, 2377, 2780], [2647, 2755, 3022], [467, 1734, 1616], [1867, 3011, 2377], [2357, 1819, 2157], [2880, 1043, 213], [483, 2558, 2275], [3024, 2647, 2567], [2509, 2326, 1919], [2880, 467, 833], [2326, 2922, 2157], [2182, 2487, 2509], [1341, 924, 2637], [2320, 1616, 2780], [1390, 1341, 2752], [2568, 2763, 2055], [3024, 2972, 2568], [2019, 2403, 1067], [2640, 1935, 2674], [2558, 1112, 1531], [2320, 342, 2150], [1198, 2136, 342], [1476, 2055, 1599], [1867, 2740, 727], [2275, 1801, 1819], [1599, 1531, 924], [2780, 2567, 2740], [1411, 2531, 2402], [2142, 2509, 1531], [483, 1043, 1891], [2880, 1718, 1067], [899, 2640, 2674], [1198, 2558, 2019], [3024, 2567, 2361], [2142, 2518, 2275], [2332, 1341, 2752], [1933, 1476, 2763], [267, 364, 1819], [2558, 2972, 2150], [2136, 2676, 2762], [1781, 2487, 2509], [2377, 2752, 2017], [1325, 1112, 2762], [2142, 2740, 2922], [899, 2749, 2637], [1043, 1476, 924], [2780, 2922, 2637], [1933, 1476, 1599], [2640, 2055, 1819], [3024, 1411, 1616], [2332, 2017, 2762], [267, 3022, 2157], [2377, 2922, 2336], [267, 1781, 2567], [2763, 2567, 2017], [1325, 2275, 1891], [2668, 364, 3022], [2726, 2763, 2752], [2972, 213, 364], [2228, 342, 1531], [213, 2361, 1819], [2518, 2668, 1819], [467, 2716, 2763], [1390, 2487, 2922], [2019, 2531, 2852], [1933, 2228, 364], [2752, 924, 1067], [2357, 2852, 342], [364, 2726, 2336], [1867, 2668, 2377], [2640, 1711, 2637], [2558, 1781, 2647], [1325, 483, 1476], [2019, 467, 1919], [899, 2852, 2403], [1112, 2780, 2509], [1043, 1097, 213], [3024, 2568, 1919], [467, 1411, 1043], [3024, 364, 2780], [2275, 2647, 3022], [25, 2509, 2336], [2531, 2403, 167], [2182, 1476, 2157], [2402, 2377, 3022], [1390, 1043, 2922], [213, 2752, 342], [1411, 2509, 833], [467, 2852, 1476], [2357, 2055, 167], [2972, 2567, 1599], [2332, 2055, 2307], [267, 1935, 1599], [2558, 2275, 1476], [2755, 2509, 833], [2320, 467, 2762], [364, 1531, 2922], [2275, 2182, 1801], [2880, 1616, 2780], [2320, 1711, 1819], [1198, 1097, 2716], [2019, 2326, 1599], [2880, 2019, 2150], [1325, 2518, 364], [1043, 833, 2568], [2676, 2055, 1819], [2640, 2403, 2674], [2755, 1718, 2567], [2852, 2668, 2922], [2228, 1935, 2150], [2019, 342, 2150], [1198, 1781, 1891], [2697, 2659, 1067], [2320, 1891, 2017], [1734, 2647, 2659], [2647, 2726, 2326], [1781, 2235, 2150], [2369, 1599, 2659], [2320, 1198, 3022], [2332, 1734, 1891], [1043, 2377, 2763], [1935, 364, 3022], [2228, 1718, 2922], [2518, 2852, 1819], [1718, 1819, 2637], [1411, 2055, 1341], [3011, 1341, 2752], [2716, 1734, 2752], [1043, 2755, 2762], [2852, 2326, 2017], [1043, 1112, 3022], [2647, 2307, 2336], [1411, 2697, 2740], [2880, 2716, 2697], [2275, 25, 2568], [2716, 364, 2157], [2716, 2307, 2336], [1390, 1718, 2361], [2755, 2017, 727], [1325, 2357, 2780], [2647, 3022, 2157], [267, 2275, 2763], [2332, 2136, 2752], [2518, 2668, 2336], [2518, 2763, 2659], [3024, 1043, 2637], [2326, 342, 2307], [2275, 1935, 727], [899, 2357, 2377], [1734, 2235, 2922], [2558, 1867, 1067], [267, 2668, 2017], [3022, 2922, 1919], [1933, 2749, 2377], [3024, 2749, 2922], [3024, 2852, 2235], [2136, 2852, 2150], [1043, 2509, 1531], [2320, 1711, 2157], [2780, 1476, 1531], [2275, 2326, 167], [467, 1718, 167], [1325, 1933, 924], [2320, 2972, 2716], [2019, 2509, 924], [2518, 25, 2659], [2852, 1781, 2752], [1718, 2780, 2771], [2647, 2752, 2157], [1112, 2922, 727], [2369, 2640, 213], [1734, 2326, 2922], [2357, 267, 2336], [2403, 1718, 1919], [2320, 2275, 727], [2880, 213, 2755], [2763, 2336, 2150], [1325, 1043, 2922], [2228, 1891, 1341], [2332, 467, 1616], [2568, 1599, 2361], [2716, 213, 2157], [1390, 1935, 1819], [1411, 1718, 1531], [2357, 2182, 2235], [1933, 2771, 2922], [2142, 1616, 2567], [1933, 3022, 2568], [364, 2509, 2762], [1390, 1781, 924], [833, 2157, 2674], [2275, 2136, 2668], [2518, 2369, 833], [2749, 2531, 2852], [2771, 1599, 2235], [1867, 2487, 1919], [1325, 2716, 1067], [2320, 364, 2567], [1867, 2755, 2674], [2749, 364, 167], [2558, 2182, 1935], [2676, 2568, 2762], [2749, 2531, 1711], [1097, 2676, 1112], [1411, 1043, 2726], [2182, 213, 2403], [899, 2402, 2403], [1325, 2531, 2055], [2640, 3011, 2755], [2320, 899, 1819], [2332, 2275, 2771], [2640, 2668, 1935], [267, 2668, 2307], [1198, 2275, 2674], [1781, 213, 2150], [2357, 25, 1616], [1867, 1801, 1718], [2755, 167, 2740], [2017, 2235, 1819], [2142, 2357, 342], [1097, 2752, 2307], [483, 1616, 2922], [1933, 2749, 2017], [899, 2531, 2716], [267, 2402, 1718], [2567, 1341, 2659], [2357, 1781, 1599], [2357, 2640, 25], [2852, 2716, 2326], [2275, 1711, 2568], [899, 2755, 2403], [25, 1599, 2307], [2182, 1112, 2307], [2531, 1718, 2157], [1390, 1341, 2150], [2019, 25, 1531], [2357, 342, 2922], [2369, 1341, 727], [1390, 2972, 2755], [1043, 2568, 2157], [2369, 2716, 2403], [2531, 1734, 2326], [1711, 2763, 1067], [213, 1801, 1599], [1933, 2142, 2676], [483, 2357, 2487], [3024, 2275, 1867], [1390, 213, 1935], [2880, 1867, 2659], [1411, 2716, 1781], [2402, 2567, 2157], [1325, 2357, 2972], [2320, 364, 2487], [1097, 1718, 1476], [1867, 1711, 1718], [1933, 2228, 1801], [899, 2403, 2326], [2852, 2726, 167], [899, 2402, 364], [2142, 267, 924], [1325, 1933, 213], [2558, 2640, 342], [1599, 2762, 2674], [899, 2716, 2755], [2402, 1476, 1819], [483, 2136, 1112], [467, 1711, 924], [2402, 2637, 2150], [1599, 2752, 2740], [1933, 364, 2055], [25, 2567, 1341], [1711, 3011, 1531], [2369, 213, 1067], [2142, 2518, 1867], [2749, 3011, 2235], [2320, 833, 1819], [2558, 2716, 1919], [1616, 1891, 2637], [364, 2487, 1801], [3024, 2228, 833], [1867, 1711, 2647], [1718, 1476, 2637], [1325, 2880, 1067], [1390, 2228, 2568], [483, 899, 467], [2531, 2402, 1043], [2275, 2326, 2659], [2487, 2403, 1067], [3024, 467, 727], [2369, 2402, 2055], [267, 1734, 2055], [2357, 1867, 1935], [213, 1891, 2017], [1599, 1531, 2307], [1411, 2567, 2235], [1781, 213, 1341], [1198, 2852, 1531], [1734, 1801, 2726], [3024, 1781, 1935], [2749, 2182, 1801], [1734, 2763, 2235], [1043, 1935, 1112], [2726, 2763, 2740], [3011, 1781, 167], [3024, 1043, 1781], [2136, 2182, 2567], [2558, 2640, 1819], [2332, 1043, 2780], [2332, 2369, 2647], [1198, 2568, 2235], [1935, 342, 2361], [1711, 1112, 1531], [1734, 2055, 1819], [1616, 2509, 2659], [2852, 1935, 1616], [2320, 1616, 2509], [2668, 1476, 2771], [2142, 25, 1112], [2320, 467, 2640], [2402, 2640, 1867], [2142, 2668, 2674], [3022, 2771, 2659], [267, 2275, 2668], [1933, 2647, 2763], [1933, 167, 1819], [2357, 1801, 1067], [1411, 1935, 2326], [2019, 2752, 1531], [2716, 1616, 1891], [2019, 1801, 2674], [2716, 2487, 924], [2019, 1390, 2228], [2332, 2752, 167], [2531, 2716, 2509], [1411, 1711, 1801], [1933, 2055, 2157], [2320, 1390, 2726], [1043, 213, 2752], [2880, 3024, 1734], [2668, 2740, 1067], [467, 2402, 2361], [2142, 2726, 2567], [2518, 1891, 1067], [1711, 2676, 2509], [2403, 3022, 2326], [2402, 25, 2509], [3022, 1476, 2697], [2755, 727, 2336], [2403, 2326, 2697], [2019, 2852, 3011], [483, 2357, 2647], [1933, 1411, 2369], [2749, 2487, 2568], [1390, 2055, 1919], [467, 1867, 924], [2357, 1801, 2336], [2972, 1616, 2922], [2647, 2403, 2637], [2880, 1734, 2182], [2019, 2487, 2377], [1198, 3011, 1919], [2402, 2647, 2740], [1097, 2640, 2771], [2402, 3011, 2752], [1390, 2852, 2647], [2357, 2780, 2752], [1411, 2403, 2674], [2716, 2361, 1531], [2357, 2749, 2568], [2275, 1711, 1599], [1043, 1867, 167], [2676, 1891, 1531], [3011, 342, 1067], [2136, 2377, 2150], [1325, 2357, 1734], [1933, 1112, 2726], [2320, 1933, 1476], [2852, 1097, 2674], [1325, 1801, 1919], [899, 2228, 924], [2716, 342, 2017], [1198, 833, 2771], [2640, 3022, 1819], [2749, 3022, 1891], [2275, 2136, 2674], [1411, 1867, 1616], [2487, 2055, 2235], [2668, 1112, 2055], [2136, 1711, 3022], [2332, 833, 2307], [2558, 213, 2336], [899, 2369, 1819], [1325, 1616, 2740], [1616, 727, 2637], [2558, 1411, 1341], [25, 167, 727], [2509, 2763, 167], [2019, 1097, 2487], [2640, 1599, 1067], [1325, 2668, 833], [1476, 2235, 2336], [3024, 2531, 2377], [1198, 1043, 167], [2182, 1891, 2157], [2749, 1599, 2150], [25, 1801, 1919], [483, 2019, 2307], [1933, 2531, 2752], [1390, 2509, 2726], [3024, 2402, 1891], [1734, 364, 2150], [2640, 2762, 1819], [1711, 1476, 2326], [1933, 1781, 2568], [3024, 2357, 833], [1043, 213, 2509], [2755, 833, 2017], [1781, 1476, 924], [2668, 2228, 2150], [2880, 2403, 2726], [2320, 2403, 342], [2755, 2659, 2150], [267, 2771, 2697], [2749, 2755, 1919], [2019, 1711, 1476], [467, 1112, 342], [2320, 25, 727], [2019, 1043, 2647], [1801, 2326, 2637], [2369, 2228, 2780], [2558, 2647, 2017], [2668, 2377, 2674], [2518, 2055, 2336], [1198, 1933, 924], [2749, 1043, 1341], [1734, 2771, 924], [267, 2518, 2182], [1781, 2228, 2377], [1734, 2771, 1919], [2668, 25, 2326], [2780, 2697, 727], [2755, 1616, 2567], [2852, 1097, 2659], [2275, 213, 1935], [364, 2922, 2157], [1711, 3022, 2922], [2142, 2749, 2136], [1325, 1891, 2336], [1801, 2157, 2336], [2332, 2326, 1341], [2403, 1801, 2326], [467, 2763, 1819], [1801, 3022, 2017], [2676, 1112, 342], [3024, 2357, 1891], [213, 833, 2017], [25, 924, 2150], [1390, 2676, 2763], [1933, 1801, 1891], [1325, 2771, 2150], [2142, 2019, 1097], [1390, 1599, 1067], [483, 2972, 1616], [483, 2518, 2361], [1933, 25, 2752], [2749, 1935, 2659], [1411, 2402, 2726], [1867, 2647, 2740], [483, 1935, 1531], [1390, 213, 25], [1411, 1616, 2637], [1711, 3011, 2647], [2357, 1411, 2726], [2518, 2568, 1531], [2019, 1781, 2055], [2019, 2531, 2659], [899, 2357, 2228], [2880, 1043, 2668], [1411, 2402, 25], [2332, 2326, 2674], [1043, 2235, 1919], [2228, 2326, 2637], [483, 2716, 2326], [3011, 25, 1718], [2369, 1718, 2726], [2668, 1734, 2326], [2369, 2403, 2922], [2332, 2697, 2017], [2880, 2275, 1919], [2142, 2531, 1919], [1325, 2568, 2361], [1411, 2972, 2157], [2558, 2509, 2326], [899, 1390, 1867], [2142, 213, 2676], [2518, 2403, 1531], [1935, 3022, 1476], [1476, 2726, 2740], [3024, 1390, 2307], [1325, 2518, 2762], [2377, 2509, 2697], [2518, 1935, 1891], [3024, 2136, 2697], [1198, 833, 1819], [1390, 1801, 727], [2880, 1476, 2752], [1616, 3022, 2307], [2369, 213, 3022], [267, 2852, 25], [1781, 2740, 1067], [833, 2771, 2697], [2880, 2771, 1819], [2320, 2487, 2150], [1891, 1341, 2336], [1711, 2771, 2235], [1198, 2403, 2336], [2749, 2972, 1097], [1097, 2647, 2307], [2880, 3024, 2972], [3024, 2518, 1819], [1097, 213, 1718], [2332, 2518, 2326], [2369, 3011, 1718], [3011, 1341, 2336], [2972, 364, 2307], [2320, 2676, 2403], [2320, 2531, 167], [1325, 2972, 2568], [1476, 2763, 167], [899, 2182, 1599], [2780, 342, 2336], [2182, 213, 1891], [1711, 1801, 2150], [2749, 1891, 1599], [2647, 2752, 1819], [2142, 2019, 2972], [1933, 2275, 2377], [2647, 2752, 1067], [1198, 1867, 342], [364, 2326, 1067], [2716, 2567, 2150], [2320, 1198, 1919], [2019, 1411, 1616], [483, 1734, 364], [1616, 2235, 2922], [899, 1097, 213], [3024, 167, 1919], [1891, 2326, 2055], [3024, 2697, 2150], [267, 1711, 2567], [2716, 2509, 2922], [1734, 213, 25], [1616, 1599, 2017], [2676, 2763, 1919], [2182, 342, 2659], [2142, 2668, 2568], [2332, 2142, 2972], [2518, 1781, 2752], [1043, 1476, 2740], [2142, 2668, 2055], [2640, 213, 2568], [1112, 2509, 1819], [2182, 2377, 2763], [2749, 833, 2762], [2922, 727, 2307], [2716, 1476, 2771], [1198, 267, 833], [899, 1718, 2762], [2640, 2361, 2674], [2357, 2697, 2740], [2749, 2676, 1476], [2403, 2922, 2157], [2136, 2055, 2637], [1891, 2922, 1819], [2880, 1867, 2762], [1616, 2771, 1067], [2558, 2332, 1390], [2487, 2403, 2762], [3024, 2531, 2676], [2142, 1067, 2150], [267, 727, 2674], [899, 3022, 1599], [2972, 1801, 1341], [267, 25, 1819], [1390, 1867, 2150], [1097, 1891, 2336], [2332, 2142, 2182], [2749, 2326, 2697], [2019, 1867, 2668], [833, 2752, 2017], [2518, 1476, 2055], [2357, 25, 1718], [2852, 2182, 2487], [2668, 1711, 2182], [2518, 2228, 1476], [483, 1390, 2361], [2142, 2369, 1819], [2852, 2567, 342], [2228, 2326, 2307], [2972, 1718, 2674], [1390, 2228, 364], [1933, 1411, 1801], [2716, 1734, 1819], [1711, 1734, 2755], [267, 2402, 1531], [1734, 2568, 2157], [1734, 167, 1819], [2972, 2726, 2697], [2275, 833, 2017], [2531, 1711, 2336], [2780, 2336, 1067], [2749, 2369, 2361], [2558, 2749, 2326], [2749, 167, 1919], [1411, 2275, 2568], [1867, 213, 1599], [2019, 2780, 2307], [213, 1341, 342], [2136, 1734, 2780], [3024, 2558, 1801], [3024, 1616, 2017], [2275, 2697, 2307], [833, 2763, 1599], [1734, 1781, 2307], [2332, 2568, 2697], [2531, 25, 2017]]\n"
          ]
        }
      ],
      "source": [
        "print(lst_all_neg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zbj-uEeG7JyL"
      },
      "outputs": [],
      "source": [
        "# combining both positive and negative complex data \n",
        "lst_combine = lst_all+lst_all_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAXLNOV68ZzN"
      },
      "outputs": [],
      "source": [
        "# making labels for positive complex data\n",
        "\n",
        "lst1 = torch.ones(int(len(lst_combine)/2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_73Y8zG8Z9Q"
      },
      "outputs": [],
      "source": [
        "# making labels for negative complex data\n",
        "\n",
        "lst2 = torch.zeros(int(len(lst_combine)/2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_R9DzYP8aAp"
      },
      "outputs": [],
      "source": [
        "# combining both positive and negative labels for complex data\n",
        "\n",
        "result_tensor = torch.cat((lst1, lst2), dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xLHiYiH9R1-",
        "outputId": "07a1c52a-80cc-4efa-af81-8673a1f122b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2236"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(result_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXyjm5ur68hT"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as f\n",
        "\n",
        "def func_concat(update,lst):\n",
        "  val = (update[lst[0]]*update[lst[1]]*update[lst[2]]).sum(dim=-1)\n",
        "  return f.relu(val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23D4z41zri8A",
        "outputId": "111a1228-9e76-429f-9e66-baee8c3eef6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1118\n"
          ]
        }
      ],
      "source": [
        "print(len(np.ones(int(len(lst_combine)/2))+np.zeros(int(len(lst_combine)/2))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ae3YzqlW68jv"
      },
      "outputs": [],
      "source": [
        "# GNN for Complex using relu activation function\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class Gnn_Layer(nn.Module):\n",
        "  def __init__(self,input_dim,output_dim):\n",
        "    super(Gnn_Layer,self).__init__()\n",
        "    self.update = nn.Linear(input_dim,output_dim)\n",
        "    self.aggregate = nn.Linear(input_dim,output_dim)\n",
        "\n",
        "  def forward(self,adj_matrix,x,edge_val):\n",
        "    messages = torch.matmul(adj_matrix,x)\n",
        "    aggregated = self.aggregate(messages)\n",
        "    updated = self.update(x)+aggregated\n",
        "\n",
        "    lst_val = []\n",
        "    for lst in lst_all:\n",
        "      lst_val.append(func_concat(updated,lst))\n",
        "\n",
        "\n",
        "    return torch.tensor(lst_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uukIp0R68mX"
      },
      "outputs": [],
      "source": [
        "model = Gnn_Layer(train_data.num_features,32)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.0005)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8QM8zsi68o3"
      },
      "outputs": [],
      "source": [
        "train_adj_matrix,train_max_val = adj_func(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-BCsssT68rS"
      },
      "outputs": [],
      "source": [
        "def func_normalize(data_value):\n",
        "  sc = StandardScaler()\n",
        "  train_x = sc.fit_transform(data_value)\n",
        "  return train_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKRPP4Yi68us"
      },
      "outputs": [],
      "source": [
        "train_loss = []\n",
        "import torch.nn.functional as F\n",
        "def train():\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  out=model(torch.Tensor(train_adj_matrix),torch.Tensor(func_normalize(train_data.x)),train_data.edge_label_index).view(-1)\n",
        "  train_labels = torch.ones(len(out))\n",
        "  loss=criterion(out,train_labels)\n",
        "  #loss = F.binary_cross_entropy_with_logits(out, train_data.edge_label)\n",
        "  #loss.backward()\n",
        "  optimizer.step()\n",
        "  train_loss.append(loss.item())\n",
        "  return loss.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjTOBczs-K-7"
      },
      "outputs": [],
      "source": [
        "test_adj_matrix,test_max_val = adj_func(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xdh1CE_7Y_4"
      },
      "outputs": [],
      "source": [
        "total_loss=[]\n",
        "test_accuracies=[]\n",
        "def test():\n",
        "  model.eval()\n",
        "  out=model(torch.Tensor(test_adj_matrix),torch.Tensor(func_normalize(test_data.x)),test_data.edge_label_index).view(-1)\n",
        "  test_labels = torch.ones(len(out))\n",
        "  loss=criterion(out,test_labels).view(-1)\n",
        "  #loss = F.binary_cross_entropy_with_logits(out, train_data.edge_label)\n",
        "  total_loss.append(loss.item())\n",
        "\n",
        "  predictions = (torch.sigmoid(out) > 0.5).float()\n",
        "  correct_predictions = (predictions == test_labels).float()\n",
        "  acc = correct_predictions.mean()\n",
        "  test_accuracies.append(acc)\n",
        "  return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhHJ6SYk7Ze8",
        "outputId": "8070879c-a747-4458-89a9-f2d639220666"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "Epoch 10, train_Loss: 0.5609989166, test_Accuracy: 0.4911\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "Epoch 20, train_Loss: 0.5609989166, test_Accuracy: 0.4911\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "Epoch 30, train_Loss: 0.5609989166, test_Accuracy: 0.4911\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "Epoch 40, train_Loss: 0.5609989166, test_Accuracy: 0.4911\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "Epoch 50, train_Loss: 0.5609989166, test_Accuracy: 0.4911\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "Epoch 60, train_Loss: 0.5609989166, test_Accuracy: 0.4911\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "Epoch 70, train_Loss: 0.5609989166, test_Accuracy: 0.4911\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "Epoch 80, train_Loss: 0.5609989166, test_Accuracy: 0.4911\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "Epoch 90, train_Loss: 0.5609989166, test_Accuracy: 0.4911\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n",
            "0.5609989166259766\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1,100):\n",
        "  loss=train()\n",
        "  print(loss)\n",
        "  if epoch % 10 == 0:\n",
        "        acc = test()\n",
        "        print(f\"Epoch {epoch}, train_Loss: {loss:.10f}, test_Accuracy: {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHvg7FDb7ZhM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Pl0SUzBscNl"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as f\n",
        "\n",
        "def func(update,lst):\n",
        "  val = [torch.concat((update[lst[0]],update[lst[1]],update[lst[2]]),dim=-1)]\n",
        "  return val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UqanOuE7Zks"
      },
      "outputs": [],
      "source": [
        "# GNN for Complex data using Classifier\n",
        "\n",
        "import torch.nn as nn\n",
        "import numpy\n",
        "\n",
        "class Gnn_Layer(nn.Module):\n",
        "  def __init__(self,input_dim,output_dim):\n",
        "    super(Gnn_Layer,self).__init__()\n",
        "    self.update = nn.Linear(input_dim,output_dim)\n",
        "    self.aggregate = nn.Linear(input_dim,output_dim)\n",
        "\n",
        "  def forward(self,adj_matrix,x,edge_val):\n",
        "    messages = torch.matmul(adj_matrix,x)\n",
        "    aggregated = self.aggregate(messages)\n",
        "    updated = self.update(x)+aggregated\n",
        "\n",
        "    lst_val = []\n",
        "    for lst in lst_combine:\n",
        "\n",
        "      lst_val.append(func(updated,lst)[0].detach().numpy())\n",
        "\n",
        "\n",
        "    return lst_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-L7c3BlUswSp"
      },
      "outputs": [],
      "source": [
        "model = Gnn_Layer(train_data.num_features,32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M_68vqq83yd",
        "outputId": "f9fcda60-1d22-4c9e-e45e-de70f6b11790"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2236\n"
          ]
        }
      ],
      "source": [
        "print(len(lst_combine))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0i00pd0s3fJ",
        "outputId": "6b323569-3299-4368-bea8-3483e71d8d6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32\n"
          ]
        }
      ],
      "source": [
        "out=model(torch.Tensor(train_adj_matrix),torch.Tensor(func_normalize(train_data.x)),train_data.edge_label_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y4Wt-Hdx_xx",
        "outputId": "f21199a4-8a4f-46f7-a440-6dc61123f8e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2236, 96)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.shape(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xOe1IoEti9n"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "labels = np.array(result_tensor.detach().numpy())\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(out,labels,test_size=0.2,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZi_b-0JuF1D"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc = SVC()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "DosN2rnEuQf3",
        "outputId": "ca9625d3-a522-4c29-82b0-61cea0e34f91"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "SVC()"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "svc.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeDQcdQ1wPsb"
      },
      "outputs": [],
      "source": [
        "y_pred = svc.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytqV8NE898p-"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHcDdvml-MWD",
        "outputId": "0f610096-3dd8-457a-b92b-7dd58398a214"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8705357142857143\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_score(y_test,y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
